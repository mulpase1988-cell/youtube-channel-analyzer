# ========================================
# YouTube ì±„ë„ ë¶„ì„ê¸° v2 - GitHub Actions ë²„ì „
# RSS + YouTube API í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹
# ========================================

# ========================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ========================================
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import datetime, timezone, timedelta
from dateutil import parser as dateutil_parser
import feedparser
import subprocess
import json
import time
import re
import urllib.parse
import traceback
import os
import tempfile

# ========================================
# 2. ì„¤ì • ë³€ìˆ˜
# ========================================

# ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
SERVICE_ACCOUNT_JSON = os.environ.get('GOOGLE_SERVICE_ACCOUNT')
if not SERVICE_ACCOUNT_JSON:
    raise Exception("âŒ GOOGLE_SERVICE_ACCOUNT í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

# JSONì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
    f.write(SERVICE_ACCOUNT_JSON)
    SERVICE_ACCOUNT_FILE = f.name

# Google Sheets ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
SHEET_NAME = os.environ.get('SHEET_NAME', 'ìœ íŠœë¸Œë³´ë¬¼ì°½ê³ _í…ŒìŠ¤íŠ¸')
API_TAB_NAME = os.environ.get('API_TAB_NAME', 'API_í‚¤_ê´€ë¦¬')
DATA_TAB_NAME = os.environ.get('DATA_TAB_NAME', 'ë°ì´í„°2')

# ì»¬ëŸ¼ ë§¤í•‘ (A=1, B=2, ...)
COL_CHANNEL_NAME = 1      # A: ì±„ë„ëª…
COL_URL = 2                # B: URL
COL_HANDLE = 3             # C: í•¸ë“¤
COL_COUNTRY = 4            # D: êµ­ê°€
COL_CATEGORY_1 = 5         # E: ë¶„ë¥˜1 (ìˆ˜ë™)
COL_CATEGORY_2 = 6         # F: ë¶„ë¥˜2 (ìˆ˜ë™)
COL_MEMO = 7               # G: ë©”ëª¨ (ìˆ˜ë™)
COL_SUBSCRIBERS = 8        # H: êµ¬ë…ì
COL_VIDEO_COUNT = 9        # I: ë™ì˜ìƒ
COL_TOTAL_VIEWS = 10       # J: ì¡°íšŒìˆ˜
COL_FIRST_UPLOAD = 11      # K: ìµœì´ˆì—…ë¡œë“œ
COL_LATEST_UPLOAD = 12     # L: ìµœê·¼ ì—…ë¡œë“œ
COL_COLLECT_DATE = 13      # M: ìˆ˜ì§‘ì¼
COL_VIEWS_5_TOTAL = 14     # N: ìµœê·¼ 5ê°œ í† íƒˆ
COL_VIEWS_10_TOTAL = 15    # O: ìµœê·¼ 10ê°œ í† íƒˆ
COL_VIEWS_20_TOTAL = 16    # P: ìµœê·¼ 20ê°œ í† íƒˆ
COL_VIEWS_30_TOTAL = 17    # Q: ìµœê·¼ 30ê°œ í† íƒˆ
COL_KEYWORD = 18           # R: í‚¤ì›Œë“œ (ìˆ˜ë™)
COL_NOTE = 19              # S: ë¹„ê³  (ìˆ˜ë™)
COL_OPERATION_DAYS = 20    # T: ìš´ì˜ê¸°ê°„
COL_TEMPLATE = 21          # U: í…œí”Œë¦¿ (ìˆ˜ë™)
COL_COUNT_5D = 22          # V: 5ì¼ ê¸°ì¤€
COL_COUNT_10D = 23         # W: 10ì¼ ê¸°ì¤€
COL_CHANNEL_ID = 24        # X: channel_id
COL_VIEWS_5D = 25          # Y: 5ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_VIEWS_10D = 26         # Z: 10ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_VIEWS_15D = 27         # AA: 15ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_YT_CATEGORY = 28       # AB: YTì¹´í…Œê³ ë¦¬
COL_VIDEO_LINKS = [29, 30, 31, 32, 33]  # AC~AG: ì˜ìƒ1~5

# ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼
MANUAL_INPUT_COLUMNS = [COL_CATEGORY_1, COL_CATEGORY_2, COL_MEMO, 
                        COL_KEYWORD, COL_NOTE, COL_TEMPLATE]

# êµ­ê°€ ì½”ë“œ â†’ í•œê¸€ ë§¤í•‘
COUNTRY_MAP = {
    'KR': 'í•œêµ­', 'US': 'ë¯¸êµ­', 'JP': 'ì¼ë³¸', 'GB': 'ì˜êµ­', 
    'DE': 'ë…ì¼', 'FR': 'í”„ë‘ìŠ¤', 'CA': 'ìºë‚˜ë‹¤', 'AU': 'í˜¸ì£¼',
    'VN': 'ë² íŠ¸ë‚¨', 'TH': 'íƒœêµ­', 'ID': 'ì¸ë„ë„¤ì‹œì•„', 'IN': 'ì¸ë„',
    'BR': 'ë¸Œë¼ì§ˆ', 'MX': 'ë©•ì‹œì½”', 'RU': 'ëŸ¬ì‹œì•„', 'TR': 'í„°í‚¤',
    'ES': 'ìŠ¤í˜ì¸', 'IT': 'ì´íƒˆë¦¬ì•„', 'TW': 'ëŒ€ë§Œ', 'HK': 'í™ì½©',
    'PH': 'í•„ë¦¬í•€', 'CN': 'ì¤‘êµ­', 'SG': 'ì‹±ê°€í¬ë¥´', 'MY': 'ë§ë ˆì´ì‹œì•„'
}

# ì¹´í…Œê³ ë¦¬ ID â†’ í•œê¸€ ë§¤í•‘
CATEGORY_MAP = {
    '1': 'ì˜í™”/ì• ë‹ˆë©”ì´ì…˜', '2': 'ìë™ì°¨/ì°¨ëŸ‰', '10': 'ìŒì•…',
    '15': 'ë°˜ë ¤ë™ë¬¼/ë™ë¬¼', '17': 'ìŠ¤í¬ì¸ ', '18': 'ë‹¨í¸ ë™ì˜ìƒ',
    '19': 'ì—¬í–‰/ì´ë²¤íŠ¸', '20': 'ê²Œì„', '21': 'ë¸Œì´ë¡œê·¸',
    '22': 'ì¸ë¬¼/ë¸”ë¡œê·¸', '23': 'ì½”ë¯¸ë””', '24': 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
    '25': 'ë‰´ìŠ¤/ì •ì¹˜', '26': 'ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼', '27': 'êµìœ¡',
    '28': 'ê³¼í•™ê¸°ìˆ ', '29': 'ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™'
}

# ========================================
# 3. í—¬í¼ í•¨ìˆ˜ë“¤
# ========================================
def get_country_name(country_code):
    """êµ­ê°€ ì½”ë“œë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜ (ë¹ˆ ê°’ì´ë©´ 'í•œêµ­' ê¸°ë³¸ê°’)"""
    if not country_code or country_code.strip() == '':
        return 'í•œêµ­'
    return COUNTRY_MAP.get(country_code.upper(), country_code)

def get_category_name(category_id):
    """ì¹´í…Œê³ ë¦¬ IDë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜"""
    if not category_id:
        return 'ë¯¸ë¶„ë¥˜'
    return CATEGORY_MAP.get(str(category_id), 'ë¯¸ë¶„ë¥˜')

def get_video_url(video_id):
    """ì˜ìƒ IDë¡œ YouTube URL ìƒì„±"""
    if not video_id:
        return ''
    return f"https://www.youtube.com/watch?v={video_id}"

def get_video_urls(video_ids, max_count=5):
    """ìƒìœ„ 5ê°œ ì˜ìƒì˜ YouTube URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    urls = []
    for vid in video_ids[:max_count]:
        urls.append(get_video_url(vid))
    while len(urls) < max_count:
        urls.append('')
    return urls

def parse_published_date(date_str):
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±"""
    if not date_str:
        return None
    try:
        dt = dateutil_parser.parse(date_str)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except Exception as e:
        print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str} | {e}")
        return None

# ========================================
# 4. API í‚¤ ë§¤ë‹ˆì €
# ========================================
class YouTubeAPIKeyManager:
    """YouTube API í‚¤ ê´€ë¦¬ ë° ì¿¼í„° ì¶”ì """

    def __init__(self, service_account_file, sheet_name, api_tab_name):
        self.service_account_file = service_account_file
        self.sheet_name = sheet_name
        self.api_tab_name = api_tab_name

        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            service_account_file, scope)
        self.gc = gspread.authorize(creds)

        try:
            spreadsheet = self.gc.open(sheet_name)
            self.api_sheet = spreadsheet.worksheet(api_tab_name)
            print(f"âœ… '{api_tab_name}' ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ '{api_tab_name}' ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

        self.api_keys = []
        self.quota_status = {}
        self.current_date = datetime.now(timezone.utc).strftime('%Y-%m-%d')

        self.load_keys_from_sheet()
        print(f"âœ… API í‚¤ {len(self.api_keys)}ê°œ ë¡œë“œ ì™„ë£Œ\n")

    def load_keys_from_sheet(self):
        """ì‹œíŠ¸ì—ì„œ API í‚¤ ë° ì‚¬ìš©ëŸ‰ ë¡œë“œ"""
        try:
            all_values = self.api_sheet.get_all_values()

            if len(all_values) < 4:
                print("âš ï¸  API í‚¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return

            headers = all_values[2]

            try:
                idx_name = headers.index('í‚¤ ì´ë¦„')
                idx_key = headers.index('API í‚¤')
                idx_active = headers.index('í™œì„±í™”')
                idx_quota = headers.index('í• ë‹¹ëŸ‰ (ì „ì²´)')
                idx_used = headers.index('ì‚¬ìš©ëŸ‰')
            except ValueError as e:
                print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                print(f"   ì‹¤ì œ í—¤ë”: {headers}")
                raise

            for row_idx, row in enumerate(all_values[3:], start=4):
                if len(row) <= max(idx_name, idx_key, idx_active):
                    continue

                key_name = row[idx_name].strip()
                api_key = row[idx_key].strip()
                active = row[idx_active]

                is_active = str(active).upper() in ['TRUE', 'YES', 'Y', 'O', 'í™œì„±', 'ì‚¬ìš©']

                if not key_name or not api_key or not is_active:
                    continue

                try:
                    total_quota = int(row[idx_quota]) if idx_quota < len(row) and row[idx_quota] else 10000
                    used_quota = int(row[idx_used]) if idx_used < len(row) and row[idx_used] else 0
                except:
                    total_quota = 10000
                    used_quota = 0

                self.api_keys.append({
                    'name': key_name,
                    'key': api_key,
                    'row': row_idx,
                    'active': True
                })

                self.quota_status[key_name] = {
                    'total': total_quota,
                    'used': used_quota,
                    'remaining': total_quota - used_quota,
                    'errors': 0,
                    'last_reset': self.current_date,
                    'session_used': 0
                }

                print(f"  âœ“ {key_name}: {api_key[:20]}... (í• ë‹¹ëŸ‰: {total_quota}, ì‚¬ìš©: {used_quota})")

        except Exception as e:
            print(f"âŒ API í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            raise

    def get_key_for_row(self, row_number, required_quota=110):
        """íŠ¹ì • í–‰ì— í• ë‹¹ëœ API í‚¤ ë°˜í™˜"""
        if not self.api_keys:
            raise Exception("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")

        key_idx = (row_number - 4) % len(self.api_keys)
        selected_key = self.api_keys[key_idx]
        key_name = selected_key['name']

        status = self.quota_status[key_name]
        if status['remaining'] >= required_quota:
            return selected_key

        for backup_key in self.api_keys:
            backup_name = backup_key['name']
            backup_status = self.quota_status[backup_name]
            if backup_status['remaining'] >= required_quota:
                return backup_key

        raise Exception(f"âŒ ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")

    def update_quota_used(self, key_name, units):
        """API í‚¤ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
        if key_name in self.quota_status:
            self.quota_status[key_name]['used'] += units
            self.quota_status[key_name]['remaining'] -= units
            self.quota_status[key_name]['session_used'] += units

    def sync_to_sheet(self):
        """ë©”ëª¨ë¦¬ì˜ ì‚¬ìš©ëŸ‰ì„ ì‹œíŠ¸ì— ë™ê¸°í™” (ë°°ì¹˜ ì—…ë°ì´íŠ¸)"""
        try:
            print("\n  ğŸ”„ API í‚¤ ì‚¬ìš©ëŸ‰ ì‹œíŠ¸ ë™ê¸°í™” ì¤‘...")
            
            all_values = self.api_sheet.get_all_values()
            headers = all_values[2]
            
            idx_name = headers.index('í‚¤ ì´ë¦„')
            idx_used = headers.index('ì‚¬ìš©ëŸ‰') + 1
            idx_remaining = headers.index('ë‚¨ì€ëŸ‰') + 1
            idx_rate = headers.index('ì‚¬ìš©ë¥  (%)') + 1
            idx_last_used = headers.index('ë§ˆì§€ë§‰ ì‚¬ìš©') + 1
            
            cell_list = []
            
            for key_info in self.api_keys:
                key_name = key_info['name']
                row_num = key_info['row']
                
                if key_name not in self.quota_status:
                    continue
                
                status = self.quota_status[key_name]
                
                cell_list.append(gspread.Cell(row_num, idx_used, status['used']))
                cell_list.append(gspread.Cell(row_num, idx_remaining, status['remaining']))
                
                usage_rate = (status['used'] / status['total'] * 100) if status['total'] > 0 else 0
                cell_list.append(gspread.Cell(row_num, idx_rate, f"{usage_rate:.2f}%"))
                
                if status['session_used'] > 0:
                    last_used = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
                    cell_list.append(gspread.Cell(row_num, idx_last_used, last_used))
            
            if cell_list:
                self.api_sheet.update_cells(cell_list)
                print(f"  âœ… API í‚¤ ì‚¬ìš©ëŸ‰ ì‹œíŠ¸ ë™ê¸°í™” ì™„ë£Œ ({len(cell_list)}ê°œ ì…€)")
            
        except Exception as e:
            print(f"  âš ï¸  ì‹œíŠ¸ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            traceback.print_exc()

    def print_status(self):
        """í˜„ì¬ API í‚¤ ìƒíƒœ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š API í‚¤ í• ë‹¹ëŸ‰ í˜„í™©")
        print("="*80)

        total_used = 0
        total_remaining = 0

        for key_name, status in self.quota_status.items():
            total_used += status['used']
            total_remaining += status['remaining']
            
            print(f"  {key_name:15s} | "
                  f"ì „ì²´: {status['total']:6,d} | "
                  f"ì‚¬ìš©: {status['used']:6,d} | "
                  f"ë‚¨ìŒ: {status['remaining']:6,d} | "
                  f"ì„¸ì…˜: {status['session_used']:6,d}")

        print("-"*80)
        print(f"  {'ì „ì²´ í•©ê³„':15s} | "
              f"ì‚¬ìš©: {total_used:6,d} | "
              f"ë‚¨ìŒ: {total_remaining:6,d}")
        print("="*80 + "\n")

# ========================================
# 5. RSS í”¼ë“œ íŒŒì‹±
# ========================================
def parse_rss_feed(channel_id, max_videos=15):
    """YouTube RSS í”¼ë“œì—ì„œ ìµœê·¼ ì˜ìƒ ì •ë³´ ì¶”ì¶œ"""
    rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"

    try:
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            return []

        videos = []
        for entry in feed.entries[:max_videos]:
            video_id = entry.yt_videoid if hasattr(entry, 'yt_videoid') else None
            if not video_id and 'id' in entry:
                video_id = entry.id.split(':')[-1]

            published_str = entry.published if hasattr(entry, 'published') else None
            published_at = None
            if published_str:
                try:
                    from email.utils import parsedate_to_datetime
                    published_at = parsedate_to_datetime(published_str)
                except:
                    pass

            videos.append({
                'video_id': video_id,
                'title': entry.title if hasattr(entry, 'title') else '',
                'published_at': published_at
            })

        return videos

    except Exception as e:
        print(f"  âš ï¸  RSS í”¼ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []

# ========================================
# 6. ì±„ë„ ID ì¶”ì¶œ
# ========================================
def extract_channel_id_from_url(channel_url, api_manager, row_number, row_data=None):
    """ì±„ë„ URLì—ì„œ channel_id ì¶”ì¶œ"""
    if '/channel/' in channel_url:
        return channel_url.split('/channel/')[-1].split('/')[0].split('?')[0]

    handle_from_sheet = None
    if row_data and len(row_data) >= COL_HANDLE:
        handle_from_sheet = str(row_data[COL_HANDLE - 1]).strip()

        if handle_from_sheet:
            if handle_from_sheet.startswith('@'):
                handle_from_sheet = handle_from_sheet[1:]

            try:
                handle_decoded = urllib.parse.unquote(handle_from_sheet)
                print(f"  ğŸ“‹ Cì—´ì—ì„œ í•¸ë“¤ ì‚¬ìš©: @{handle_decoded}")
            except:
                handle_decoded = handle_from_sheet

            try:
                api_key_info = api_manager.get_key_for_row(row_number, required_quota=1)
                api_key = api_key_info['key']
                key_name = api_key_info['name']

                youtube = build('youtube', 'v3', developerKey=api_key)

                channel_response = youtube.channels().list(
                    part='id',
                    forHandle=handle_decoded,
                    maxResults=1
                ).execute()

                api_manager.update_quota_used(key_name, 1)

                if channel_response['items']:
                    channel_id = channel_response['items'][0]['id']
                    print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (Cì—´ + forHandle): {channel_id}")
                    return channel_id
            except Exception as e:
                print(f"  âš ï¸  Cì—´ í•¸ë“¤ë¡œ forHandle ì‹¤íŒ¨: {e}")

    decoded_url = urllib.parse.unquote(channel_url)
    handle_match = re.search(r'@([^/\s?]+)', decoded_url)
    
    if not handle_match:
        print(f"  âš ï¸  URLì—ì„œ í•¸ë“¤ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ")
        return None

    handle = handle_match.group(1)
    print(f"  ğŸ“ URLì—ì„œ í•¸ë“¤ ì¶”ì¶œ: @{handle}")

    try:
        api_key_info = api_manager.get_key_for_row(row_number, required_quota=1)
        api_key = api_key_info['key']
        key_name = api_key_info['name']

        youtube = build('youtube', 'v3', developerKey=api_key)

        channel_response = youtube.channels().list(
            part='id',
            forHandle=handle,
            maxResults=1
        ).execute()

        api_manager.update_quota_used(key_name, 1)

        if channel_response['items']:
            channel_id = channel_response['items'][0]['id']
            print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (URL + forHandle): {channel_id}")
            return channel_id
    except Exception as e:
        print(f"  âš ï¸  forHandle ì‹¤íŒ¨: {e}")

    try:
        import requests
        clean_url = channel_url.split('/shorts')[0].split('/videos')[0].split('/streams')[0]
        response = requests.get(clean_url, timeout=10)

        patterns = [
            r'"channelId":"([^"]+)"',
            r'"externalId":"([^"]+)"',
        ]

        for pattern in patterns:
            match = re.search(pattern, response.text)
            if match:
                channel_id = match.group(1)
                print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (ì›¹ ìŠ¤í¬ë˜í•‘): {channel_id}")
                return channel_id
    except Exception as e:
        print(f"  âš ï¸  ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")

    return None

def extract_channel_id_ytdlp(url):
    """yt-dlpë¡œ ì±„ë„ ID ì¶”ì¶œ"""
    try:
        result = subprocess.run(
            ['yt-dlp', '--dump-json', '--playlist-items', '1', url],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            data = json.loads(result.stdout)
            return data.get('channel_id')
    except Exception as e:
        print(f"âš ï¸ yt-dlp ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return None

# ========================================
# 7. ë©”ì¸ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
# ========================================
def get_channel_data_hybrid(channel_url, api_manager, row_number, row_data, worksheet):
    """RSS + API í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘"""
    result = {
        'channel_name': '',
        'handle': '',
        'country': '',
        'subscribers': 0,
        'video_count': 0,
        'total_views': 0,
        'first_upload': '',
        'latest_upload': '',
        'collect_date': datetime.now(timezone.utc).strftime('%Y-%m-%d'),
        'views_5': 0,
        'views_10': 0,
        'views_20': 0,
        'views_30': 0,
        'views_5d': 0,
        'views_10d': 0,
        'views_15d': 0,
        'count_5d': 0,
        'count_10d': 0,
        'operation_days': 0,
        'channel_id': '',
        'yt_category': 'ë¯¸ë¶„ë¥˜',
        'video_links': ['', '', '', '', '']
    }

    try:
        existing_channel_id = ''
        if len(row_data) >= COL_CHANNEL_ID:
            existing_channel_id = str(row_data[COL_CHANNEL_ID - 1]).strip()

        channel_id = existing_channel_id

        if not channel_id:
            print(f"  ğŸ“ channel_id ì—†ìŒ, ê²€ìƒ‰ í•„ìš”...")
            channel_id = extract_channel_id_from_url(
                channel_url,
                api_manager,
                row_number,
                row_data=row_data
            )

            if not channel_id:
                print(f"  âŒ channel_id ì¶”ì¶œ ì‹¤íŒ¨, yt-dlpë¡œ ë°±ì—… ì‹œë„")
                channel_id = extract_channel_id_ytdlp(channel_url)
                
                if not channel_id:
                    return None

            try:
                cell_list = [gspread.Cell(row_number, COL_CHANNEL_ID, channel_id)]
                worksheet.update_cells(cell_list)
                print(f"  âœ… channel_id ì €ì¥ ì™„ë£Œ: {channel_id}")
                time.sleep(2)
            except Exception as e:
                print(f"  âš ï¸  channel_id ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            print(f"  âœ“ ê¸°ì¡´ channel_id ì‚¬ìš©: {channel_id}")

        result['channel_id'] = channel_id

        print(f"  ğŸ“¡ RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘...")
        rss_videos = parse_rss_feed(channel_id, max_videos=15)
        print(f"  âœ“ RSSì—ì„œ {len(rss_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘")

        api_key_info = api_manager.get_key_for_row(row_number, required_quota=3)
        api_key = api_key_info['key']
        key_name = api_key_info['name']

        youtube = build('youtube', 'v3', developerKey=api_key)

        channel_response = youtube.channels().list(
            part='snippet,statistics,contentDetails',
            id=channel_id
        ).execute()

        api_manager.update_quota_used(key_name, 1)

        if not channel_response['items']:
            print(f"  âŒ ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None

        channel_info = channel_response['items'][0]
        snippet = channel_info['snippet']
        statistics = channel_info['statistics']

        result['channel_name'] = snippet.get('title', '')
        result['handle'] = snippet.get('customUrl', '')
        
        country_code = snippet.get('country', '').strip()
        if not country_code:
            result['country'] = 'í•œêµ­'
            print(f"  â„¹ï¸  êµ­ê°€ ì •ë³´ ì—†ìŒ â†’ 'í•œêµ­'ìœ¼ë¡œ ì„¤ì •")
        else:
            result['country'] = get_country_name(country_code)
            print(f"  â„¹ï¸  êµ­ê°€: {result['country']} ({country_code})")

        result['subscribers'] = int(statistics.get('subscriberCount', 0))
        result['video_count'] = int(statistics.get('videoCount', 0))
        result['total_views'] = int(statistics.get('viewCount', 0))

        print(f"  âœ“ ì±„ë„: {result['channel_name']}")
        print(f"  âœ“ êµ¬ë…ì: {result['subscribers']:,} | ì˜ìƒ: {result['video_count']:,}")

        uploads_playlist_id = channel_info['contentDetails']['relatedPlaylists']['uploads']

        playlist_response = youtube.playlistItems().list(
            part='contentDetails',
            playlistId=uploads_playlist_id,
            maxResults=30
        ).execute()

        api_manager.update_quota_used(key_name, 1)

        api_videos = []
        for item in playlist_response['items'][15:30]:
            video_id = item['contentDetails']['videoId']
            api_videos.append(video_id)

        print(f"  âœ“ APIì—ì„œ {len(api_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ (16~30ë²ˆì§¸)")

        all_video_ids = [v['video_id'] for v in rss_videos if v['video_id']] + api_videos
        all_video_ids = all_video_ids[:30]

        if not all_video_ids:
            print(f"  âš ï¸  ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤")
            return result

        videos_response = youtube.videos().list(
            part='statistics,snippet',
            id=','.join(all_video_ids)
        ).execute()

        api_manager.update_quota_used(key_name, 1)

        view_map = {}
        for video in videos_response['items']:
            video_id = video['id']
            view_count = int(video['statistics'].get('viewCount', 0))
            published_str = video['snippet'].get('publishedAt', '')

            published_at = None
            if published_str:
                try:
                    published_at = datetime.fromisoformat(published_str.replace('Z', '+00:00'))
                except:
                    pass

            view_map[video_id] = (view_count, published_at)

        if videos_response['items']:
            first_category_id = videos_response['items'][0]['snippet'].get('categoryId', '')
            result['yt_category'] = get_category_name(first_category_id)

        result['video_links'] = get_video_urls([v['id'] for v in videos_response['items']], max_count=5)

        views_list = []
        for video_id in all_video_ids:
            if video_id in view_map:
                views_list.append(view_map[video_id][0])

        result['views_5'] = sum(views_list[:5])
        result['views_10'] = sum(views_list[:10])
        result['views_20'] = sum(views_list[:20])
        result['views_30'] = sum(views_list[:30])

        now = datetime.now(timezone.utc)

        views_5d_list = []
        views_10d_list = []
        views_15d_list = []

        print(f"  ğŸ“… ë‚ ì§œ ê¸°ì¤€ ì¡°íšŒìˆ˜ ê³„ì‚° (ê¸°ì¤€: {now.strftime('%Y-%m-%d %H:%M UTC')})")

        for video_id in all_video_ids:
            if video_id not in view_map:
                continue

            view_count, published_at = view_map[video_id]

            if not published_at:
                continue

            days_ago = (now - published_at).days

            if days_ago <= 15:
                print(f"    ğŸ“… {video_id}: {days_ago}ì¼ ì „ | {view_count:,}íšŒ")

            if days_ago <= 5:
                views_5d_list.append(view_count)
            if days_ago <= 10:
                views_10d_list.append(view_count)
            if days_ago <= 15:
                views_15d_list.append(view_count)

        result['views_5d'] = sum(views_5d_list)
        result['views_10d'] = sum(views_10d_list)
        result['views_15d'] = sum(views_15d_list)
        result['count_5d'] = len(views_5d_list)
        result['count_10d'] = len(views_10d_list)

        print(f"  âœ… 5ì¼: {result['views_5d']:,}íšŒ ({result['count_5d']}ê°œ)")
        print(f"  âœ… 10ì¼: {result['views_10d']:,}íšŒ ({result['count_10d']}ê°œ)")
        print(f"  âœ… 15ì¼: {result['views_15d']:,}íšŒ")

        dates = []
        for video_id in all_video_ids:
            if video_id in view_map and view_map[video_id][1]:
                dates.append(view_map[video_id][1])

        if dates:
            result['latest_upload'] = max(dates).strftime('%Y-%m-%d')
            result['first_upload'] = min(dates).strftime('%Y-%m-%d')
            first_date = min(dates)
            result['operation_days'] = (now - first_date).days

        return result

    except Exception as e:
        print(f"  âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None

# ========================================
# 8. ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼ ë³´ì¡´
# ========================================
def preserve_manual_columns(worksheet, row_num):
    """ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼ì˜ ê¸°ì¡´ ê°’ ì½ê¸°"""
    try:
        manual_values = {}
        for col in MANUAL_INPUT_COLUMNS:
            cell_value = worksheet.cell(row_num, col).value
            manual_values[col] = cell_value if cell_value else ''
        return manual_values
    except Exception as e:
        print(f"âš ï¸ ìˆ˜ë™ ì»¬ëŸ¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return {col: '' for col in MANUAL_INPUT_COLUMNS}

# ========================================
# 9. ë°°ì¹˜ ì—…ë°ì´íŠ¸
# ========================================
def update_row_batch(worksheet, row_num, data_dict, manual_values):
    """33ê°œ ì…€ì„ í•œ ë²ˆì— ì—…ë°ì´íŠ¸ (Bì—´ URLì€ ë³´ì¡´)"""
    try:
        existing_url = worksheet.cell(row_num, COL_URL).value or ''
        
        row_data = [''] * 33

        row_data[COL_CHANNEL_NAME - 1] = data_dict.get('channel_name', '')
        row_data[COL_URL - 1] = existing_url
        row_data[COL_HANDLE - 1] = data_dict.get('handle', '')
        row_data[COL_COUNTRY - 1] = data_dict.get('country', '')
        row_data[COL_SUBSCRIBERS - 1] = data_dict.get('subscribers', 0)
        row_data[COL_VIDEO_COUNT - 1] = data_dict.get('video_count', 0)
        row_data[COL_TOTAL_VIEWS - 1] = data_dict.get('total_views', 0)
        row_data[COL_FIRST_UPLOAD - 1] = data_dict.get('first_upload', '')
        row_data[COL_LATEST_UPLOAD - 1] = data_dict.get('latest_upload', '')
        row_data[COL_COLLECT_DATE - 1] = data_dict.get('collect_date', '')
        row_data[COL_VIEWS_5_TOTAL - 1] = data_dict.get('views_5', 0)
        row_data[COL_VIEWS_10_TOTAL - 1] = data_dict.get('views_10', 0)
        row_data[COL_VIEWS_20_TOTAL - 1] = data_dict.get('views_20', 0)
        row_data[COL_VIEWS_30_TOTAL - 1] = data_dict.get('views_30', 0)
        row_data[COL_OPERATION_DAYS - 1] = data_dict.get('operation_days', 0)
        row_data[COL_COUNT_5D - 1] = data_dict.get('count_5d', 0)
        row_data[COL_COUNT_10D - 1] = data_dict.get('count_10d', 0)
        row_data[COL_CHANNEL_ID - 1] = data_dict.get('channel_id', '')
        row_data[COL_VIEWS_5D - 1] = data_dict.get('views_5d', 0)
        row_data[COL_VIEWS_10D - 1] = data_dict.get('views_10d', 0)
        row_data[COL_VIEWS_15D - 1] = data_dict.get('views_15d', 0)
        row_data[COL_YT_CATEGORY - 1] = data_dict.get('yt_category', 'ë¯¸ë¶„ë¥˜')

        video_links = data_dict.get('video_links', [''] * 5)
        for i, col_idx in enumerate(COL_VIDEO_LINKS):
            row_data[col_idx - 1] = video_links[i]

        for col in MANUAL_INPUT_COLUMNS:
            row_data[col - 1] = manual_values.get(col, '')

        range_str = f'A{row_num}:AG{row_num}'
        worksheet.update(range_str, [row_data])

        print(f"âœ… Row {row_num} ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ (Bì—´ URL ë³´ì¡´)")
        return True

    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

# ========================================
# 10. ë©”ì¸ ì‹¤í–‰
# ========================================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“‚ YouTube ì±„ë„ ë¶„ì„ê¸° v2 - GitHub Actions ë²„ì „")
    print("=" * 60)

    try:
        print("\nğŸ“‹ API í‚¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        api_manager = YouTubeAPIKeyManager(
            SERVICE_ACCOUNT_FILE,
            SHEET_NAME,
            API_TAB_NAME
        )

        if not api_manager.api_keys:
            print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'API_í‚¤_ê´€ë¦¬' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        print(f"ğŸ“Š '{SHEET_NAME}' ì‹œíŠ¸ ì—°ê²° ì¤‘...")
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            SERVICE_ACCOUNT_FILE, scope)
        gc = gspread.authorize(creds)
        spreadsheet = gc.open(SHEET_NAME)
        worksheet = spreadsheet.worksheet(DATA_TAB_NAME)

        print("âœ… ì‹œíŠ¸ ì—°ê²° ì™„ë£Œ\n")

        print("=" * 60)
        range_input = os.environ.get('RANGE', '').strip()

        if range_input:
            if '-' in range_input:
                start_row, end_row = map(int, range_input.split('-'))
            else:
                start_row = end_row = int(range_input)
            print(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ ë²”ìœ„ ì½ê¸°: {start_row}í–‰ ~ {end_row}í–‰")
        else:
            all_data = worksheet.get_all_values()
            start_row = 2
            end_row = len(all_data)
            print(f"âœ… ì „ì²´ ì²˜ë¦¬: {start_row}í–‰ ~ {end_row}í–‰")

        print(f"ğŸ“Œ ì´ {end_row - start_row + 1}ê°œ í–‰ ì²˜ë¦¬ ì˜ˆì •")

        print("\n" + "=" * 60)
        print("ğŸš€ ì±„ë„ ë¶„ì„ ì‹œì‘")
        print("=" * 60)

        success_count = 0
        fail_count = 0
        start_time = time.time()

        for row_num in range(start_row, end_row + 1):
            print(f"\n{'='*60}")
            print(f"ğŸ” [{row_num - start_row + 1}/{end_row - start_row + 1}] ì²˜ë¦¬ ì¤‘...")
            print(f"{'='*60}")

            try:
                row_data = worksheet.row_values(row_num)
                if len(row_data) < 3:
                    print(f"â­ï¸  Row {row_num}: ë°ì´í„° ë¶€ì¡±")
                    continue

                url = row_data[COL_URL - 1] if len(row_data) >= COL_URL else ''
                handle = row_data[COL_HANDLE - 1] if len(row_data) >= COL_HANDLE else ''

                if not url and not handle:
                    print(f"â­ï¸  Row {row_num}: URL/í•¸ë“¤ ì—†ìŒ")
                    continue

                print(f"ğŸ“Œ URL: {url}")
                print(f"ğŸ“Œ í•¸ë“¤: {handle}")

                manual_values = preserve_manual_columns(worksheet, row_num)

                data = get_channel_data_hybrid(url, api_manager, row_num, row_data, worksheet)

                if not data:
                    print(f"âŒ Row {row_num}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    fail_count += 1
                    continue

                if update_row_batch(worksheet, row_num, data, manual_values):
                    success_count += 1
                    print(f"âœ… Row {row_num} ì™„ë£Œ!")
                else:
                    fail_count += 1

                if (row_num - start_row + 1) % 5 == 0:
                    api_manager.sync_to_sheet()
                    api_manager.print_status()
                    print(f"ğŸ’¤ 30ì´ˆ ëŒ€ê¸°...")
                    time.sleep(30)
                else:
                    time.sleep(3)

            except Exception as e:
                print(f"âŒ Row {row_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                traceback.print_exc()
                fail_count += 1
                continue

        elapsed_time = time.time() - start_time
        print("\n" + "=" * 60)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼")
        print("=" * 60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time / 60:.1f}ë¶„")
        if (success_count + fail_count) > 0:
            print(f"âš¡ í‰ê·  ì†ë„: {elapsed_time / (success_count + fail_count):.1f}ì´ˆ/ì±„ë„")
        print("=" * 60)

        api_manager.sync_to_sheet()
        api_manager.print_status()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

# ========================================
# 11. ì‹¤í–‰
# ========================================
if __name__ == '__main__':
    main()
