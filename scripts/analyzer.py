# ========================================
# YouTube ì±„ë„ ë¶„ì„ê¸° v2 - GitHub Actions ë²„ì „
# RSS + YouTube API í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ + Shorts ì±„ë„ + ì¬ì‹œë„ ë¡œì§ + ë°°ì¹˜ ì—…ë°ì´íŠ¸ (20í–‰) + ë°°ì¹˜ ì½ê¸°
# âœ… ìˆ˜ì •1: ì˜ìƒ ë§í¬ â†’ ì¸ë„¤ì¼ URLë¡œ ë³€ê²½
# âœ… ìˆ˜ì •2: ìš´ì˜ê¸°ê°„(Tì—´) = Lì—´(ìµœê·¼ ì—…ë¡œë“œ) - Kì—´(ìµœì´ˆ ì—…ë¡œë“œ)
# ========================================

# ========================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ========================================
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import datetime, timezone, timedelta
from dateutil import parser as dateutil_parser
import feedparser
import subprocess
import json
import time
import re
import urllib.parse
import traceback
import os
import tempfile
import random

# ========================================
# 2. ì„¤ì • ë³€ìˆ˜
# ========================================

# ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
SERVICE_ACCOUNT_JSON = os.environ.get('GOOGLE_SERVICE_ACCOUNT')
if not SERVICE_ACCOUNT_JSON:
    raise Exception("âŒ GOOGLE_SERVICE_ACCOUNT í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

# JSONì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
    f.write(SERVICE_ACCOUNT_JSON)
    SERVICE_ACCOUNT_FILE = f.name

# Google Sheets ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
SHEET_NAME = os.environ.get('SHEET_NAME', 'ìœ íŠœë¸Œë³´ë¬¼ì°½ê³ _í…ŒìŠ¤íŠ¸')
API_TAB_NAME = os.environ.get('API_TAB_NAME', 'API_í‚¤_ê´€ë¦¬')
DATA_TAB_NAME = os.environ.get('DATA_TAB_NAME', 'ë°ì´í„°')

# ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì„¤ì •
BATCH_SIZE = 20  # 20í–‰ì”© ë°°ì¹˜ ì²˜ë¦¬

# ì»¬ëŸ¼ ë§¤í•‘ (A=1, B=2, ...)
COL_CHANNEL_NAME = 1      # A: ì±„ë„ëª…
COL_URL = 2                # B: URL
COL_HANDLE = 3             # C: í•¸ë“¤
COL_COUNTRY = 4            # D: êµ­ê°€
COL_CATEGORY_1 = 5         # E: ë¶„ë¥˜1 (ìˆ˜ë™)
COL_CATEGORY_2 = 6         # F: ë¶„ë¥˜2 (ìˆ˜ë™)
COL_MEMO = 7               # G: ë©”ëª¨ (ìˆ˜ë™)
COL_SUBSCRIBERS = 8        # H: êµ¬ë…ì
COL_VIDEO_COUNT = 9        # I: ë™ì˜ìƒ
COL_TOTAL_VIEWS = 10       # J: ì¡°íšŒìˆ˜
COL_FIRST_UPLOAD = 11      # K: ìµœì´ˆì—…ë¡œë“œ
COL_LATEST_UPLOAD = 12     # L: ìµœê·¼ ì—…ë¡œë“œ
COL_COLLECT_DATE = 13      # M: ìˆ˜ì§‘ì¼
COL_VIEWS_5_TOTAL = 14     # N: ìµœê·¼ 5ê°œ í† íƒˆ
COL_VIEWS_10_TOTAL = 15    # O: ìµœê·¼ 10ê°œ í† íƒˆ
COL_VIEWS_20_TOTAL = 16    # P: ìµœê·¼ 20ê°œ í† íƒˆ
COL_VIEWS_30_TOTAL = 17    # Q: ìµœê·¼ 30ê°œ í† íƒˆ
COL_KEYWORD = 18           # R: í‚¤ì›Œë“œ (ìˆ˜ë™)
COL_NOTE = 19              # S: ë¹„ê³  (ìˆ˜ë™)
COL_OPERATION_DAYS = 20    # T: ìš´ì˜ê¸°ê°„
COL_TEMPLATE = 21          # U: í…œí”Œë¦¿ (ìˆ˜ë™)
COL_COUNT_5D = 22          # V: 5ì¼ ê¸°ì¤€
COL_COUNT_10D = 23         # W: 10ì¼ ê¸°ì¤€
COL_CHANNEL_ID = 24        # X: channel_id
COL_VIEWS_5D = 25          # Y: 5ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_VIEWS_10D = 26         # Z: 10ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_VIEWS_15D = 27         # AA: 15ì¼ì¡°íšŒìˆ˜í•©ê³„
COL_YT_CATEGORY = 28       # AB: YTì¹´í…Œê³ ë¦¬
COL_VIDEO_LINKS = [29, 30, 31, 32, 33]  # AC~AG: ì¸ë„¤ì¼1~5

# ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼
MANUAL_INPUT_COLUMNS = [COL_CATEGORY_1, COL_CATEGORY_2, COL_MEMO, 
                        COL_KEYWORD, COL_NOTE, COL_TEMPLATE]

# ì¬ì‹œë„ ì„¤ì •
MAX_RETRIES = 3
RETRY_DELAY = 2  # ì´ˆ
RATE_LIMIT_WAIT = 60  # Rate Limit ì‹œ ëŒ€ê¸° ì‹œê°„

# êµ­ê°€ ì½”ë“œ â†’ í•œê¸€ ë§¤í•‘
COUNTRY_MAP = {
    'KR': 'í•œêµ­', 'US': 'ë¯¸êµ­', 'JP': 'ì¼ë³¸', 'GB': 'ì˜êµ­', 
    'DE': 'ë…ì¼', 'FR': 'í”„ë‘ìŠ¤', 'CA': 'ìºë‚˜ë‹¤', 'AU': 'í˜¸ì£¼',
    'VN': 'ë² íŠ¸ë‚¨', 'TH': 'íƒœêµ­', 'ID': 'ì¸ë„ë„¤ì‹œì•„', 'IN': 'ì¸ë„',
    'BR': 'ë¸Œë¼ì§ˆ', 'MX': 'ë©•ì‹œì½”', 'RU': 'ëŸ¬ì‹œì•„', 'TR': 'í„°í‚¤',
    'ES': 'ìŠ¤í˜ì¸', 'IT': 'ì´íƒˆë¦¬ì•„', 'TW': 'ëŒ€ë§Œ', 'HK': 'í™ì½©',
    'PH': 'í•„ë¦¬í•€', 'CN': 'ì¤‘êµ­', 'SG': 'ì‹±ê°€í¬ë¥´', 'MY': 'ë§ë ˆì´ì‹œì•„'
}

# ì¹´í…Œê³ ë¦¬ ID â†’ í•œê¸€ ë§¤í•‘
CATEGORY_MAP = {
    '1': 'ì˜í™”/ì• ë‹ˆë©”ì´ì…˜', '2': 'ìë™ì°¨/ì°¨ëŸ‰', '10': 'ìŒì•…',
    '15': 'ë°˜ë ¤ë™ë¬¼/ë™ë¬¼', '17': 'ìŠ¤í¬ì¸ ', '18': 'ë‹¨í¸ ë™ì˜ìƒ',
    '19': 'ì—¬í–‰/ì´ë²¤íŠ¸', '20': 'ê²Œì„', '21': 'ë¸Œì´ë¡œê·¸',
    '22': 'ì¸ë¬¼/ë¸”ë¡œê·¸', '23': 'ì½”ë¯¸ë””', '24': 'ì—”í„°í…Œì¸ë¨¼íŠ¸',
    '25': 'ë‰´ìŠ¤/ì •ì¹˜', '26': 'ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼', '27': 'êµìœ¡',
    '28': 'ê³¼í•™ê¸°ìˆ ', '29': 'ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™'
}

# ========================================
# 3. ì¬ì‹œë„ ë°ì½”ë ˆì´í„°
# ========================================
def retry_with_backoff(func):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•œ ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return func(*args, **kwargs)
            except HttpError as e:
                # 429: Rate Limit
                if e.resp.status == 429:
                    wait_time = RATE_LIMIT_WAIT * (2 ** attempt) + random.uniform(0, 1)
                    print(f"  âš ï¸  Rate Limit ê°ì§€! {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{MAX_RETRIES})...")
                    time.sleep(wait_time)
                    continue
                # 500: ì„œë²„ ì˜¤ë¥˜
                elif e.resp.status >= 500:
                    wait_time = RETRY_DELAY * (2 ** attempt)
                    print(f"  âš ï¸  ì„œë²„ ì˜¤ë¥˜ ({e.resp.status})! {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{MAX_RETRIES})...")
                    time.sleep(wait_time)
                    continue
                # ê¸°íƒ€ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ë°˜í™˜
                else:
                    raise
            except Exception as e:
                # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± ì¼ì‹œì  ì˜¤ë¥˜ëŠ” ì¬ì‹œë„
                if attempt < MAX_RETRIES - 1:
                    wait_time = RETRY_DELAY * (2 ** attempt)
                    print(f"  âš ï¸  ì¼ì‹œì  ì˜¤ë¥˜: {str(e)[:50]}... {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{MAX_RETRIES})...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise
        
        raise Exception(f"âŒ {MAX_RETRIES}íšŒ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨")
    
    return wrapper

# ========================================
# 4. í—¬í¼ í•¨ìˆ˜ë“¤
# ========================================
def get_country_name(country_code):
    """êµ­ê°€ ì½”ë“œë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜ (ë¹ˆ ê°’ì´ë©´ 'í•œêµ­' ê¸°ë³¸ê°’)"""
    if not country_code or country_code.strip() == '':
        return 'í•œêµ­'
    return COUNTRY_MAP.get(country_code.upper(), country_code)

def get_category_name(category_id):
    """ì¹´í…Œê³ ë¦¬ IDë¥¼ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜"""
    if not category_id:
        return 'ë¯¸ë¶„ë¥˜'
    return CATEGORY_MAP.get(str(category_id), 'ë¯¸ë¶„ë¥˜')

def get_thumbnail_urls(video_infos, max_count=5):
    """âœ… ìˆ˜ì •: ìƒìœ„ 5ê°œ ì˜ìƒì˜ ì¸ë„¤ì¼ URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ê³ í•´ìƒë„ ìš°ì„ )"""
    urls = []
    for video_info in video_infos[:max_count]:
        try:
            # ì¸ë„¤ì¼ URL ì„ íƒ ìš°ì„ ìˆœìœ„: maxres > standard > high > medium > default
            thumbnails = video_info.get('thumbnails', {})
            
            thumbnail_url = (
                thumbnails.get('maxres', {}).get('url') or      # ìµœê³  í•´ìƒë„ (1280x720)
                thumbnails.get('standard', {}).get('url') or    # í‘œì¤€ (640x480)
                thumbnails.get('high', {}).get('url') or        # ë†’ìŒ (320x180)
                thumbnails.get('medium', {}).get('url') or      # ì¤‘ê°„ (320x180)
                thumbnails.get('default', {}).get('url') or     # ê¸°ë³¸ (120x90)
                ''
            )
            urls.append(thumbnail_url)
        except Exception as e:
            print(f"  âš ï¸  ì¸ë„¤ì¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            urls.append('')
    
    # ë¶€ì¡±í•œ ì¹¸ ì±„ìš°ê¸°
    while len(urls) < max_count:
        urls.append('')
    
    return urls

def parse_published_date(date_str):
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±"""
    if not date_str:
        return None
    try:
        dt = dateutil_parser.parse(date_str)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except Exception as e:
        print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str} | {e}")
        return None

# ========================================
# 5. API í‚¤ ë§¤ë‹ˆì €
# ========================================
class YouTubeAPIKeyManager:
    """YouTube API í‚¤ ê´€ë¦¬ ë° ì¿¼í„° ì¶”ì """

    def __init__(self, service_account_file, sheet_name, api_tab_name):
        self.service_account_file = service_account_file
        self.sheet_name = sheet_name
        self.api_tab_name = api_tab_name

        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            service_account_file, scope)
        self.gc = gspread.authorize(creds)

        try:
            spreadsheet = self.gc.open(sheet_name)
            self.api_sheet = spreadsheet.worksheet(api_tab_name)
            print(f"âœ… '{api_tab_name}' ì‹œíŠ¸ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ '{api_tab_name}' ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

        self.api_keys = []
        self.quota_status = {}
        self.current_date = datetime.now(timezone.utc).strftime('%Y-%m-%d')

        self.load_keys_from_sheet()
        print(f"âœ… API í‚¤ {len(self.api_keys)}ê°œ ë¡œë“œ ì™„ë£Œ\n")

    def load_keys_from_sheet(self):
        """ì‹œíŠ¸ì—ì„œ API í‚¤ ë° ì‚¬ìš©ëŸ‰ ë¡œë“œ"""
        try:
            all_values = self.api_sheet.get_all_values()

            if len(all_values) < 4:
                print("âš ï¸  API í‚¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return

            headers = all_values[2]

            try:
                idx_name = headers.index('í‚¤ ì´ë¦„')
                idx_key = headers.index('API í‚¤')
                idx_active = headers.index('í™œì„±í™”')
                idx_quota = headers.index('í• ë‹¹ëŸ‰ (ì „ì²´)')
                idx_used = headers.index('ì‚¬ìš©ëŸ‰')
            except ValueError as e:
                print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                print(f"   ì‹¤ì œ í—¤ë”: {headers}")
                raise

            for row_idx, row in enumerate(all_values[3:], start=4):
                if len(row) <= max(idx_name, idx_key, idx_active):
                    continue

                key_name = row[idx_name].strip()
                api_key = row[idx_key].strip()
                active = row[idx_active]

                is_active = str(active).upper() in ['TRUE', 'YES', 'Y', 'O', 'í™œì„±', 'ì‚¬ìš©']

                if not key_name or not api_key or not is_active:
                    continue

                try:
                    total_quota = int(row[idx_quota]) if idx_quota < len(row) and row[idx_quota] else 10000
                    used_quota = int(row[idx_used]) if idx_used < len(row) and row[idx_used] else 0
                except:
                    total_quota = 10000
                    used_quota = 0

                self.api_keys.append({
                    'name': key_name,
                    'key': api_key,
                    'row': row_idx,
                    'active': True
                })

                self.quota_status[key_name] = {
                    'total': total_quota,
                    'used': used_quota,
                    'remaining': total_quota - used_quota,
                    'errors': 0,
                    'last_reset': self.current_date,
                    'session_used': 0
                }

                print(f"  âœ“ {key_name}: {api_key[:20]}... (í• ë‹¹ëŸ‰: {total_quota}, ì‚¬ìš©: {used_quota})")

        except Exception as e:
            print(f"âŒ API í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            raise

    def get_key_for_row(self, row_number, required_quota=110):
        """íŠ¹ì • í–‰ì— í• ë‹¹ëœ API í‚¤ ë°˜í™˜"""
        if not self.api_keys:
            raise Exception("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")

        key_idx = (row_number - 4) % len(self.api_keys)
        selected_key = self.api_keys[key_idx]
        key_name = selected_key['name']

        status = self.quota_status[key_name]
        if status['remaining'] >= required_quota:
            return selected_key

        for backup_key in self.api_keys:
            backup_name = backup_key['name']
            backup_status = self.quota_status[backup_name]
            if backup_status['remaining'] >= required_quota:
                return backup_key

        raise Exception(f"âŒ ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")

    def update_quota_used(self, key_name, units):
        """API í‚¤ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
        if key_name in self.quota_status:
            self.quota_status[key_name]['used'] += units
            self.quota_status[key_name]['remaining'] -= units
            self.quota_status[key_name]['session_used'] += units

    def sync_to_sheet(self):
        """ë©”ëª¨ë¦¬ì˜ ì‚¬ìš©ëŸ‰ì„ ì‹œíŠ¸ì— ë™ê¸°í™” (ë°°ì¹˜ ì—…ë°ì´íŠ¸)"""
        try:
            print("\n  ğŸ”„ API í‚¤ ì‚¬ìš©ëŸ‰ ì‹œíŠ¸ ë™ê¸°í™” ì¤‘...")
            
            all_values = self.api_sheet.get_all_values()
            headers = all_values[2]
            
            idx_name = headers.index('í‚¤ ì´ë¦„')
            idx_used = headers.index('ì‚¬ìš©ëŸ‰') + 1
            idx_remaining = headers.index('ë‚¨ì€ëŸ‰') + 1
            idx_rate = headers.index('ì‚¬ìš©ë¥  (%)') + 1
            idx_last_used = headers.index('ë§ˆì§€ë§‰ ì‚¬ìš©') + 1
            
            cell_list = []
            
            for key_info in self.api_keys:
                key_name = key_info['name']
                row_num = key_info['row']
                
                if key_name not in self.quota_status:
                    continue
                
                status = self.quota_status[key_name]
                
                cell_list.append(gspread.Cell(row_num, idx_used, status['used']))
                cell_list.append(gspread.Cell(row_num, idx_remaining, status['remaining']))
                
                usage_rate = (status['used'] / status['total'] * 100) if status['total'] > 0 else 0
                cell_list.append(gspread.Cell(row_num, idx_rate, f"{usage_rate:.2f}%"))
                
                if status['session_used'] > 0:
                    last_used = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
                    cell_list.append(gspread.Cell(row_num, idx_last_used, last_used))
            
            if cell_list:
                self.api_sheet.update_cells(cell_list)
                print(f"  âœ… API í‚¤ ì‚¬ìš©ëŸ‰ ì‹œíŠ¸ ë™ê¸°í™” ì™„ë£Œ ({len(cell_list)}ê°œ ì…€)")
            
        except Exception as e:
            print(f"  âš ï¸  ì‹œíŠ¸ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            traceback.print_exc()

    def print_status(self):
        """í˜„ì¬ API í‚¤ ìƒíƒœ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š API í‚¤ í• ë‹¹ëŸ‰ í˜„í™©")
        print("="*80)

        total_used = 0
        total_remaining = 0

        for key_name, status in self.quota_status.items():
            total_used += status['used']
            total_remaining += status['remaining']
            
            print(f"  {key_name:15s} | "
                  f"ì „ì²´: {status['total']:6,d} | "
                  f"ì‚¬ìš©: {status['used']:6,d} | "
                  f"ë‚¨ìŒ: {status['remaining']:6,d} | "
                  f"ì„¸ì…˜: {status['session_used']:6,d}")

        print("-"*80)
        print(f"  {'ì „ì²´ í•©ê³„':15s} | "
              f"ì‚¬ìš©: {total_used:6,d} | "
              f"ë‚¨ìŒ: {total_remaining:6,d}")
        print("="*80 + "\n")

# ========================================
# 6. RSS í”¼ë“œ íŒŒì‹±
# ========================================
def parse_rss_feed(channel_id, max_videos=15):
    """YouTube RSS í”¼ë“œì—ì„œ ìµœê·¼ ì˜ìƒ ì •ë³´ ì¶”ì¶œ"""
    rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"

    try:
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            return []

        videos = []
        for entry in feed.entries[:max_videos]:
            try:
                video_id = entry.yt_videoid if hasattr(entry, 'yt_videoid') else None
                if not video_id and 'id' in entry:
                    video_id = entry.id.split(':')[-1]

                published_str = entry.published if hasattr(entry, 'published') else None
                published_at = None
                if published_str:
                    try:
                        from email.utils import parsedate_to_datetime
                        published_at = parsedate_to_datetime(published_str)
                    except:
                        pass

                videos.append({
                    'video_id': video_id,
                    'title': entry.title if hasattr(entry, 'title') else '',
                    'published_at': published_at
                })
            except Exception as e:
                print(f"  âš ï¸  RSS í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue

        return videos

    except Exception as e:
        print(f"  âš ï¸  RSS í”¼ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []

# ========================================
# 7. ì±„ë„ ID ì¶”ì¶œ
# ========================================
def extract_channel_id_from_url(channel_url, api_manager, row_number, row_data=None):
    """ì±„ë„ URLì—ì„œ channel_id ì¶”ì¶œ"""
    if '/channel/' in channel_url:
        return channel_url.split('/channel/')[-1].split('/')[0].split('?')[0]

    handle_from_sheet = None
    if row_data and len(row_data) >= COL_HANDLE:
        handle_from_sheet = str(row_data[COL_HANDLE - 1]).strip()

        if handle_from_sheet:
            if handle_from_sheet.startswith('@'):
                handle_from_sheet = handle_from_sheet[1:]

            try:
                handle_decoded = urllib.parse.unquote(handle_from_sheet)
                print(f"  ğŸ“‹ Cì—´ì—ì„œ í•¸ë“¤ ì‚¬ìš©: @{handle_decoded}")
            except:
                handle_decoded = handle_from_sheet

            try:
                api_key_info = api_manager.get_key_for_row(row_number, required_quota=1)
                api_key = api_key_info['key']
                key_name = api_key_info['name']

                youtube = build('youtube', 'v3', developerKey=api_key)

                @retry_with_backoff
                def call_api():
                    return youtube.channels().list(
                        part='id',
                        forHandle=handle_decoded,
                        maxResults=1
                    ).execute()

                channel_response = call_api()
                api_manager.update_quota_used(key_name, 1)

                if channel_response['items']:
                    channel_id = channel_response['items'][0]['id']
                    print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (Cì—´ + forHandle): {channel_id}")
                    return channel_id
            except Exception as e:
                print(f"  âš ï¸  Cì—´ í•¸ë“¤ë¡œ forHandle ì‹¤íŒ¨: {e}")

    decoded_url = urllib.parse.unquote(channel_url)
    handle_match = re.search(r'@([^/\s?]+)', decoded_url)
    
    if not handle_match:
        print(f"  âš ï¸  URLì—ì„œ í•¸ë“¤ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ")
        return None

    handle = handle_match.group(1)
    print(f"  ğŸ“ URLì—ì„œ í•¸ë“¤ ì¶”ì¶œ: @{handle}")

    try:
        api_key_info = api_manager.get_key_for_row(row_number, required_quota=1)
        api_key = api_key_info['key']
        key_name = api_key_info['name']

        youtube = build('youtube', 'v3', developerKey=api_key)

        @retry_with_backoff
        def call_api():
            return youtube.channels().list(
                part='id',
                forHandle=handle,
                maxResults=1
            ).execute()

        channel_response = call_api()
        api_manager.update_quota_used(key_name, 1)

        if channel_response['items']:
            channel_id = channel_response['items'][0]['id']
            print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (URL + forHandle): {channel_id}")
            return channel_id
    except Exception as e:
        print(f"  âš ï¸  forHandle ì‹¤íŒ¨: {e}")

    try:
        import requests
        clean_url = channel_url.split('/shorts')[0].split('/videos')[0].split('/streams')[0]
        response = requests.get(clean_url, timeout=10)

        patterns = [
            r'"channelId":"([^"]+)"',
            r'"externalId":"([^"]+)"',
        ]

        for pattern in patterns:
            match = re.search(pattern, response.text)
            if match:
                channel_id = match.group(1)
                print(f"  âœ“ ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (ì›¹ ìŠ¤í¬ë˜í•‘): {channel_id}")
                return channel_id
    except Exception as e:
        print(f"  âš ï¸  ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")

    return None

def extract_channel_id_ytdlp(url):
    """yt-dlpë¡œ ì±„ë„ ID ì¶”ì¶œ"""
    try:
        result = subprocess.run(
            ['yt-dlp', '--dump-json', '--playlist-items', '1', url],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            data = json.loads(result.stdout)
            return data.get('channel_id')
    except Exception as e:
        print(f"âš ï¸ yt-dlp ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return None

# ========================================
# 8. Shorts ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
# ========================================
def get_shorts_channel_data(channel_id, youtube, api_manager, key_name):
    """Shorts ì „ìš© ì±„ë„ì—ì„œ ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘"""
    api_videos = []
    
    print(f"  ğŸ¬ í™œë™ í”¼ë“œì—ì„œ Shorts ê²€ìƒ‰ ì¤‘...")
    try:
        @retry_with_backoff
        def call_activities():
            return youtube.activities().list(
                part='contentDetails',
                channelId=channel_id,
                maxResults=50
            ).execute()

        activities_response = call_activities()
        api_manager.update_quota_used(key_name, 1)
        
        # Activitiesì—ì„œ video ID ì¶”ì¶œ
        for activity in activities_response.get('items', []):
            try:
                content = activity.get('contentDetails', {})
                if 'upload' in content:
                    video_id = content['upload'].get('videoId')
                    if video_id:
                        api_videos.append(video_id)
            except Exception as e:
                print(f"  âš ï¸  í™œë™ í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        print(f"  âœ“ í™œë™ í”¼ë“œì—ì„œ {len(api_videos)}ê°œ ì˜ìƒ ì¶”ì¶œ")
        
        if not api_videos:
            print(f"  âš ï¸  í™œë™ í”¼ë“œì—ì„œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
        
        # ì¶”ì¶œí•œ ì˜ìƒì˜ duration í™•ì¸í•´ì„œ Shortsë§Œ í•„í„°ë§
        api_videos = api_videos[:30]
        
        @retry_with_backoff
        def call_videos():
            return youtube.videos().list(
                part='contentDetails',
                id=','.join(api_videos)
            ).execute()

        videos_response = call_videos()
        api_manager.update_quota_used(key_name, 1)
        
        shorts_video_ids = []
        for video in videos_response.get('items', []):
            try:
                duration_str = video['contentDetails'].get('duration', '')
                
                # ISO 8601 í˜•ì‹ íŒŒì‹± (PT1M30S = 1ë¶„ 30ì´ˆ)
                import re as regex_module
                match = regex_module.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration_str)
                if match:
                    hours = int(match.group(1) or 0)
                    minutes = int(match.group(2) or 0)
                    seconds = int(match.group(3) or 0)
                    total_seconds = hours * 3600 + minutes * 60 + seconds
                    
                    # Shorts: 60ì´ˆ ì´í•˜
                    if total_seconds <= 60:
                        shorts_video_ids.append(video['id'])
            except Exception as e:
                print(f"  âš ï¸  ì˜ìƒ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        print(f"  âœ“ Shorts í•„í„°ë§ ì™„ë£Œ: {len(shorts_video_ids)}ê°œ Shorts ìˆ˜ì§‘")
        return shorts_video_ids
    
    except Exception as e:
        print(f"  âš ï¸  í™œë™ í”¼ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

# ========================================
# 9. ë©”ì¸ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
# ========================================
def get_channel_data_hybrid(channel_url, api_manager, row_number, row_data, worksheet):
    """RSS + API í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì±„ë„ ë°ì´í„° ìˆ˜ì§‘ (Shorts ì±„ë„ + ê°œì„¤ì¼ + ì„ íƒì  ì—…ë°ì´íŠ¸)"""
    result = {
        'channel_name': '',
        'handle': '',
        'country': '',
        'subscribers': 0,
        'video_count': 0,
        'total_views': 0,
        'first_upload': '',
        'latest_upload': '',
        'collect_date': datetime.now(timezone.utc).strftime('%Y-%m-%d'),
        'views_5': 0,
        'views_10': 0,
        'views_20': 0,
        'views_30': 0,
        'views_5d': 0,
        'views_10d': 0,
        'views_15d': 0,
        'count_5d': 0,
        'count_10d': 0,
        'operation_days': 0,
        'channel_id': '',
        'yt_category': 'ë¯¸ë¶„ë¥˜',
        'video_links': ['', '', '', '', '']
    }

    try:
        existing_channel_id = ''
        if len(row_data) >= COL_CHANNEL_ID:
            existing_channel_id = str(row_data[COL_CHANNEL_ID - 1]).strip()

        channel_id = existing_channel_id

        if not channel_id:
            print(f"  ğŸ“ channel_id ì—†ìŒ, ê²€ìƒ‰ í•„ìš”...")
            channel_id = extract_channel_id_from_url(
                channel_url,
                api_manager,
                row_number,
                row_data=row_data
            )

            if not channel_id:
                print(f"  âŒ channel_id ì¶”ì¶œ ì‹¤íŒ¨, yt-dlpë¡œ ë°±ì—… ì‹œë„")
                channel_id = extract_channel_id_ytdlp(channel_url)
                
                if not channel_id:
                    return None

            try:
                cell_list = [gspread.Cell(row_number, COL_CHANNEL_ID, channel_id)]
                worksheet.update_cells(cell_list)
                print(f"  âœ… channel_id ì €ì¥ ì™„ë£Œ: {channel_id}")
                time.sleep(2)
            except Exception as e:
                print(f"  âš ï¸  channel_id ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            print(f"  âœ“ ê¸°ì¡´ channel_id ì‚¬ìš©: {channel_id}")

        result['channel_id'] = channel_id

        print(f"  ğŸ“¡ RSS í”¼ë“œ ìˆ˜ì§‘ ì¤‘...")
        rss_videos = parse_rss_feed(channel_id, max_videos=15)
        print(f"  âœ“ RSSì—ì„œ {len(rss_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘")

        api_key_info = api_manager.get_key_for_row(row_number, required_quota=110)
        api_key = api_key_info['key']
        key_name = api_key_info['name']

        youtube = build('youtube', 'v3', developerKey=api_key)

        @retry_with_backoff
        def call_channels():
            return youtube.channels().list(
                part='snippet,statistics,contentDetails',
                id=channel_id
            ).execute()

        channel_response = call_channels()
        api_manager.update_quota_used(key_name, 1)

        if not channel_response['items']:
            print(f"  âŒ ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None

        channel_info = channel_response['items'][0]
        snippet = channel_info['snippet']
        statistics = channel_info['statistics']

        result['channel_name'] = snippet.get('title', '')
        result['handle'] = snippet.get('customUrl', '')
        
        country_code = snippet.get('country', '').strip()
        if not country_code:
            result['country'] = 'í•œêµ­'
            print(f"  â„¹ï¸  êµ­ê°€ ì •ë³´ ì—†ìŒ â†’ 'í•œêµ­'ìœ¼ë¡œ ì„¤ì •")
        else:
            result['country'] = get_country_name(country_code)
            print(f"  â„¹ï¸  êµ­ê°€: {result['country']} ({country_code})")

        result['subscribers'] = int(statistics.get('subscriberCount', 0))
        result['video_count'] = int(statistics.get('videoCount', 0))
        result['total_views'] = int(statistics.get('viewCount', 0))

        print(f"  âœ“ ì±„ë„: {result['channel_name']}")
        print(f"  âœ“ êµ¬ë…ì: {result['subscribers']:,} | ì˜ìƒ: {result['video_count']:,} | ì´ì¡°íšŒìˆ˜: {result['total_views']:,}")

        # âœ… ì±„ë„ ê°œì„¤ì¼ ì €ì¥ (ë¹„ìš© 0 - ì´ë¯¸ ë°›ì€ ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
        channel_created = snippet.get('publishedAt', '')
        if channel_created:
            channel_created_date = channel_created[:10]  # YYYY-MM-DD
            print(f"  ğŸ“… ì±„ë„ ê°œì„¤ì¼: {channel_created_date}")
        else:
            channel_created_date = ''

        uploads_playlist_id = channel_info['contentDetails']['relatedPlaylists']['uploads']

        # âœ… Shorts ì „ìš© ì±„ë„ ì²˜ë¦¬
        api_videos = []
        is_shorts_only = False

        try:
            @retry_with_backoff
            def call_playlist():
                return youtube.playlistItems().list(
                    part='contentDetails',
                    playlistId=uploads_playlist_id,
                    maxResults=30
                ).execute()

            playlist_response = call_playlist()
            api_manager.update_quota_used(key_name, 1)
            
            # ì¼ë°˜ ì˜ìƒ ì¶”ì¶œ
            for item in playlist_response.get('items', [])[15:30]:
                try:
                    video_id = item['contentDetails']['videoId']
                    api_videos.append(video_id)
                except Exception as e:
                    print(f"  âš ï¸  í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            print(f"  âœ“ APIì—ì„œ {len(api_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ (16~30ë²ˆì§¸)")
            
        except HttpError as e:
            if e.resp.status == 404:
                # ğŸ¬ Shorts ì „ìš© ì±„ë„ ê°ì§€
                print(f"  âš ï¸  ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì—†ìŒ â†’ Shorts ì „ìš© ì±„ë„ ê°ì§€!")
                is_shorts_only = True
                api_manager.update_quota_used(key_name, 1)
                
                # Activities APIë¡œ Shorts ì¡°íšŒ
                api_videos = get_shorts_channel_data(channel_id, youtube, api_manager, key_name)
            else:
                raise

        all_video_ids = [v['video_id'] for v in rss_videos if v['video_id']] + api_videos
        all_video_ids = all_video_ids[:30]

        if not all_video_ids:
            print(f"  âš ï¸  ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤")
            # âœ… ì˜ìƒì´ ì—†ì„ ë•Œ ì±„ë„ ê°œì„¤ì¼ ì‚¬ìš©
            if channel_created_date and not result['first_upload']:
                result['first_upload'] = channel_created_date
                result['latest_upload'] = channel_created_date
                result['operation_days'] = 0  # âœ… ìˆ˜ì •: Kì—´ê³¼ Lì—´ì´ ê°™ìœ¼ë©´ 0
                print(f"  âœ… ìµœì´ˆì—…ë¡œë“œ (ì±„ë„ ê°œì„¤ì¼): {result['first_upload']}")
                print(f"  âœ… ìµœê·¼ì—…ë¡œë“œ: {result['latest_upload']}")
                print(f"  âœ… ìš´ì˜ê¸°ê°„: {result['operation_days']}ì¼")
            return result

        @retry_with_backoff
        def call_videos():
            return youtube.videos().list(
                part='statistics,snippet',
                id=','.join(all_video_ids)
            ).execute()

        videos_response = call_videos()
        api_manager.update_quota_used(key_name, 1)

        view_map = {}
        video_infos = []  # âœ… ì¶”ê°€: ì¸ë„¤ì¼ ì •ë³´ ì €ì¥

        for video in videos_response.get('items', []):
            try:
                video_id = video['id']
                view_count = int(video['statistics'].get('viewCount', 0))
                published_str = video['snippet'].get('publishedAt', '')

                published_at = None
                if published_str:
                    try:
                        published_at = datetime.fromisoformat(published_str.replace('Z', '+00:00'))
                    except:
                        pass

                view_map[video_id] = (view_count, published_at)
                
                # âœ… ì¶”ê°€: ì¸ë„¤ì¼ ì •ë³´ ì €ì¥
                try:
                    thumbnails = video['snippet'].get('thumbnails', {})
                    video_infos.append({
                        'id': video_id,
                        'thumbnails': thumbnails
                    })
                except Exception as e:
                    print(f"  âš ï¸  ì¸ë„¤ì¼ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ ({video_id}): {e}")
                    video_infos.append({'id': video_id, 'thumbnails': {}})
                    
            except Exception as e:
                print(f"  âš ï¸  ë¹„ë””ì˜¤ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue

        if videos_response.get('items'):
            try:
                first_category_id = videos_response['items'][0]['snippet'].get('categoryId', '')
                result['yt_category'] = get_category_name(first_category_id)
            except:
                pass

        # âœ… ìˆ˜ì •: ì˜ìƒ ë§í¬ ëŒ€ì‹  ì¸ë„¤ì¼ URL ì €ì¥
        result['video_links'] = get_thumbnail_urls(video_infos, max_count=5)
        print(f"  âœ… ì¸ë„¤ì¼ URL ìˆ˜ì§‘ ì™„ë£Œ: {len([u for u in result['video_links'] if u])}ê°œ")

        views_list = []
        for video_id in all_video_ids:
            if video_id in view_map:
                views_list.append(view_map[video_id][0])

        result['views_5'] = sum(views_list[:5])
        result['views_10'] = sum(views_list[:10])
        result['views_20'] = sum(views_list[:20])
        result['views_30'] = sum(views_list[:30])

        now = datetime.now(timezone.utc)

        views_5d_list = []
        views_10d_list = []
        views_15d_list = []

        print(f"  ğŸ“… ë‚ ì§œ ê¸°ì¤€ ì¡°íšŒìˆ˜ ê³„ì‚° (ê¸°ì¤€: {now.strftime('%Y-%m-%d %H:%M UTC')})")

        for video_id in all_video_ids:
            if video_id not in view_map:
                continue

            try:
                view_count, published_at = view_map[video_id]

                if not published_at:
                    continue

                days_ago = (now - published_at).days

                if days_ago <= 15:
                    print(f"    ğŸ“… {video_id}: {days_ago}ì¼ ì „ | {view_count:,}íšŒ")

                if days_ago <= 5:
                    views_5d_list.append(view_count)
                if days_ago <= 10:
                    views_10d_list.append(view_count)
                if days_ago <= 15:
                    views_15d_list.append(view_count)
            except Exception as e:
                print(f"  âš ï¸  ì¡°íšŒìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue

        result['views_5d'] = sum(views_5d_list)
        result['views_10d'] = sum(views_10d_list)
        result['views_15d'] = sum(views_15d_list)
        result['count_5d'] = len(views_5d_list)
        result['count_10d'] = len(views_10d_list)

        print(f"  âœ… 5ì¼: {result['views_5d']:,}íšŒ ({result['count_5d']}ê°œ)")
        print(f"  âœ… 10ì¼: {result['views_10d']:,}íšŒ ({result['count_10d']}ê°œ)")
        print(f"  âœ… 15ì¼: {result['views_15d']:,}íšŒ")

        dates = []
        for video_id in all_video_ids:
            if video_id in view_map and view_map[video_id][1]:
                dates.append(view_map[video_id][1])

        # âœ… ìˆ˜ì •: Kì—´ - Lì—´ ê¸°ì¤€ìœ¼ë¡œ ìš´ì˜ê¸°ê°„ ê³„ì‚°
        if dates:
            latest_date = max(dates)      # Lì—´: ìµœê·¼ ì—…ë¡œë“œ
            first_date = min(dates)       # Kì—´: ìµœì´ˆ ì—…ë¡œë“œ
            
            result['latest_upload'] = latest_date.strftime('%Y-%m-%d')
            result['first_upload'] = first_date.strftime('%Y-%m-%d')
            
            # â­â­â­ í•µì‹¬ ìˆ˜ì •: ìš´ì˜ê¸°ê°„ = ìµœê·¼ ì—…ë¡œë“œ - ìµœì´ˆ ì—…ë¡œë“œ
            result['operation_days'] = (latest_date - first_date).days
            
            print(f"  âœ… ìµœì´ˆì—…ë¡œë“œ (Kì—´): {result['first_upload']}")
            print(f"  âœ… ìµœê·¼ì—…ë¡œë“œ (Lì—´): {result['latest_upload']}")
            print(f"  âœ… ìš´ì˜ê¸°ê°„ (Tì—´): {result['operation_days']}ì¼")
            
        elif channel_created_date:
            # ì˜ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì±„ë„ ê°œì„¤ì¼ ì‚¬ìš©
            result['first_upload'] = channel_created_date
            result['latest_upload'] = channel_created_date
            result['operation_days'] = 0  # âœ… ìˆ˜ì •: Kì—´ê³¼ Lì—´ì´ ê°™ìœ¼ë©´ 0
            
            try:
                print(f"  âœ… ìµœì´ˆì—…ë¡œë“œ (ì±„ë„ ê°œì„¤ì¼): {result['first_upload']}")
                print(f"  âœ… ìµœê·¼ì—…ë¡œë“œ: {result['latest_upload']}")
                print(f"  âœ… ìš´ì˜ê¸°ê°„: {result['operation_days']}ì¼ (ì˜ìƒ ì—†ìŒ)")
            except:
                pass

        return result

    except Exception as e:
        print(f"  âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None

# ========================================
# 10. ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼ ë³´ì¡´ (ë°°ì¹˜ ì½ê¸° ë°©ì‹)
# ========================================

def preserve_manual_columns_batch(all_sheet_data, row_num):
    """ë°°ì¹˜ ì½ê¸°ëœ ë°ì´í„°ì—ì„œ ìˆ˜ë™ ì»¬ëŸ¼ ê°’ ì¶”ì¶œ"""
    try:
        row_idx = row_num - 1
        if row_idx >= len(all_sheet_data):
            return {col: '' for col in MANUAL_INPUT_COLUMNS}
        
        row_data = all_sheet_data[row_idx]
        manual_values = {}
        
        for col in MANUAL_INPUT_COLUMNS:
            # ë©”ëª¨ë¦¬ì—ì„œ ì½ê¸° (Sheets API í˜¸ì¶œ ì—†ìŒ!)
            cell_value = row_data[col - 1] if len(row_data) >= col else ''
            manual_values[col] = cell_value if cell_value else ''
        
        return manual_values
    except Exception as e:
        print(f"âš ï¸ ìˆ˜ë™ ì»¬ëŸ¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {col: '' for col in MANUAL_INPUT_COLUMNS}

# ========================================
# 11. ë°°ì¹˜ ì—…ë°ì´íŠ¸ (20í–‰ì”©)
# ========================================
def build_cell_list(row_num, data_dict, manual_values, row_data):
    """í–‰ ë°ì´í„°ë¥¼ ì…€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    cell_list = []
    
    try:
        existing_url = row_data[COL_URL - 1] if len(row_data) >= COL_URL else ''
        existing_video_count = str(row_data[COL_VIDEO_COUNT - 1]).strip() if len(row_data) >= COL_VIDEO_COUNT else ''
        existing_total_views = str(row_data[COL_TOTAL_VIEWS - 1]).strip() if len(row_data) >= COL_TOTAL_VIEWS else ''
        
        # ê° ì»¬ëŸ¼ë³„ë¡œ ì…€ ì¶”ê°€ (ê°’ì´ ìˆì„ ë•Œë§Œ)
        columns_data = [
            (COL_CHANNEL_NAME, data_dict.get('channel_name', '')),
            (COL_URL, existing_url),  # URLì€ ìœ ì§€
            (COL_HANDLE, data_dict.get('handle', '')),
            (COL_COUNTRY, data_dict.get('country', '')),
            (COL_SUBSCRIBERS, data_dict.get('subscribers', 0)),
            (COL_VIDEO_COUNT, data_dict.get('video_count', 0) if not existing_video_count else existing_video_count),
            (COL_TOTAL_VIEWS, data_dict.get('total_views', 0) if not existing_total_views else existing_total_views),
            (COL_FIRST_UPLOAD, data_dict.get('first_upload', '')),
            (COL_LATEST_UPLOAD, data_dict.get('latest_upload', '')),
            (COL_COLLECT_DATE, data_dict.get('collect_date', '')),
            (COL_VIEWS_5_TOTAL, data_dict.get('views_5', 0)),
            (COL_VIEWS_10_TOTAL, data_dict.get('views_10', 0)),
            (COL_VIEWS_20_TOTAL, data_dict.get('views_20', 0)),
            (COL_VIEWS_30_TOTAL, data_dict.get('views_30', 0)),
            (COL_OPERATION_DAYS, data_dict.get('operation_days', 0)),  # âœ… Tì—´: ìˆ˜ì •ëœ ê³„ì‚°ê°’
            (COL_COUNT_5D, data_dict.get('count_5d', 0)),
            (COL_COUNT_10D, data_dict.get('count_10d', 0)),
            (COL_CHANNEL_ID, data_dict.get('channel_id', '')),
            (COL_VIEWS_5D, data_dict.get('views_5d', 0)),
            (COL_VIEWS_10D, data_dict.get('views_10d', 0)),
            (COL_VIEWS_15D, data_dict.get('views_15d', 0)),
            (COL_YT_CATEGORY, data_dict.get('yt_category', 'ë¯¸ë¶„ë¥˜')),
        ]
        
        for col_idx, value in columns_data:
            if value or value == 0:  # 0ë„ í¬í•¨
                cell_list.append(gspread.Cell(row_num, col_idx, value))
        
        # âœ… ìˆ˜ì •: ì¸ë„¤ì¼ URL ì €ì¥ (AC~AG)
        video_links = data_dict.get('video_links', [''] * 5)
        for i, col_idx in enumerate(COL_VIDEO_LINKS):
            if video_links[i]:
                cell_list.append(gspread.Cell(row_num, col_idx, video_links[i]))
        
        # ìˆ˜ë™ ì…ë ¥ ì»¬ëŸ¼
        for col, value in manual_values.items():
            if value:
                cell_list.append(gspread.Cell(row_num, col, value))
        
        return cell_list
    
    except Exception as e:
        print(f"âŒ ì…€ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨ (Row {row_num}): {e}")
        return []

# ========================================
# 12. ë©”ì¸ ì‹¤í–‰
# ========================================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“‚ YouTube ì±„ë„ ë¶„ì„ê¸° v2 - GitHub Actions ë²„ì „")
    print("âœ… ìˆ˜ì •1: ì˜ìƒ ë§í¬ â†’ ì¸ë„¤ì¼ URLë¡œ ë³€ê²½")
    print("âœ… ìˆ˜ì •2: ìš´ì˜ê¸°ê°„(Tì—´) = Lì—´(ìµœê·¼ ì—…ë¡œë“œ) - Kì—´(ìµœì´ˆ ì—…ë¡œë“œ)")
    print("=" * 60)

    try:
        print("\nğŸ“‹ API í‚¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        api_manager = YouTubeAPIKeyManager(
            SERVICE_ACCOUNT_FILE,
            SHEET_NAME,
            API_TAB_NAME
        )

        if not api_manager.api_keys:
            print("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'API_í‚¤_ê´€ë¦¬' íƒ­ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        print(f"ğŸ“Š '{SHEET_NAME}' ì‹œíŠ¸ ì—°ê²° ì¤‘...")
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            SERVICE_ACCOUNT_FILE, scope)
        gc = gspread.authorize(creds)
        spreadsheet = gc.open(SHEET_NAME)
        worksheet = spreadsheet.worksheet(DATA_TAB_NAME)

        print("âœ… ì‹œíŠ¸ ì—°ê²° ì™„ë£Œ\n")

        print("=" * 60)
        range_input = os.environ.get('RANGE', '').strip()

        if range_input:
            if '-' in range_input:
                start_row, end_row = map(int, range_input.split('-'))
            else:
                start_row = end_row = int(range_input)
            print(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ ë²”ìœ„ ì½ê¸°: {start_row}í–‰ ~ {end_row}í–‰")
        else:
            all_data = worksheet.get_all_values()
            start_row = 2
            end_row = len(all_data)
            print(f"âœ… ì „ì²´ ì²˜ë¦¬: {start_row}í–‰ ~ {end_row}í–‰")

        print(f"ğŸ“Œ ì´ {end_row - start_row + 1}ê°œ í–‰ ì²˜ë¦¬ ì˜ˆì •")
        print(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}í–‰ì”© ì²˜ë¦¬\n")

        # âœ… í•œë²ˆì— ëª¨ë“  ë°ì´í„° ì½ê¸° (ì½ê¸° ìš”ì²­ 1íšŒë¡œ ì œí•œ)
        print("ğŸ“¥ ì‹œíŠ¸ ë°ì´í„° ì¼ê´„ ë¡œë“œ ì¤‘...")
        all_sheet_data = worksheet.get_all_values()
        print(f"âœ… {len(all_sheet_data)}í–‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ì½ê¸° ìš”ì²­: 1íšŒ)\n")

        print("=" * 60)
        print("ğŸš€ ì±„ë„ ë¶„ì„ ì‹œì‘")
        print("=" * 60)

        success_count = 0
        fail_count = 0
        start_time = time.time()
        
        # âœ… ë°°ì¹˜ ì—…ë°ì´íŠ¸ìš© ì…€ ë¦¬ìŠ¤íŠ¸
        batch_cells = []
        batch_rows_count = 0

        for row_num in range(start_row, end_row + 1):
            print(f"\n{'='*60}")
            print(f"ğŸ” [{row_num - start_row + 1}/{end_row - start_row + 1}] ì²˜ë¦¬ ì¤‘...")
            print(f"{'='*60}")

            try:
                # âœ… ì‹œíŠ¸ì—ì„œ ì½ê¸° ëŒ€ì‹  ë©”ëª¨ë¦¬ ë°ì´í„° ì‚¬ìš©
                row_idx = row_num - 1
                if row_idx >= len(all_sheet_data):
                    print(f"â­ï¸  Row {row_num}: ë°ì´í„° ì—†ìŒ")
                    continue
                
                row_data = all_sheet_data[row_idx]
                
                if len(row_data) < 3:
                    print(f"â­ï¸  Row {row_num}: ë°ì´í„° ë¶€ì¡±")
                    continue

                url = row_data[COL_URL - 1] if len(row_data) >= COL_URL else ''
                handle = row_data[COL_HANDLE - 1] if len(row_data) >= COL_HANDLE else ''

                if not url and not handle:
                    print(f"â­ï¸  Row {row_num}: URL/í•¸ë“¤ ì—†ìŒ")
                    continue

                print(f"ğŸ“Œ URL: {url}")
                print(f"ğŸ“Œ í•¸ë“¤: {handle}")

                # âœ… ìˆ˜ì •: preserve_manual_columns_batch ì‚¬ìš©
                manual_values = preserve_manual_columns_batch(all_sheet_data, row_num)

                data = get_channel_data_hybrid(url, api_manager, row_num, row_data, worksheet)

                if not data:
                    print(f"âŒ Row {row_num}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    fail_count += 1
                    continue

                # âœ… ì…€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                cells = build_cell_list(row_num, data, manual_values, row_data)
                batch_cells.extend(cells)
                batch_rows_count += 1
                success_count += 1
                
                print(f"âœ… Row {row_num} ì¤€ë¹„ ì™„ë£Œ ({len(cells)}ê°œ ì…€)")

                # âœ… 20í–‰ë§ˆë‹¤ ë°°ì¹˜ ì—…ë°ì´íŠ¸
                if batch_rows_count >= BATCH_SIZE or row_num == end_row:
                    if batch_cells:
                        print(f"\nğŸ“¤ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰: {batch_rows_count}í–‰, {len(batch_cells)}ê°œ ì…€")
                        worksheet.update_cells(batch_cells)
                        print(f"âœ… ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                        batch_cells = []
                        batch_rows_count = 0
                        
                        # API í‚¤ ë™ê¸°í™” (20í–‰ë§ˆë‹¤)
                        api_manager.sync_to_sheet()
                        api_manager.print_status()
                        print(f"ğŸ’¤ 2ì´ˆ ëŒ€ê¸°...")
                        time.sleep(2)
                
                time.sleep(3)

            except Exception as e:
                print(f"âŒ Row {row_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                traceback.print_exc()
                fail_count += 1
                time.sleep(5)  # ì—ëŸ¬ í›„ 5ì´ˆ ëŒ€ê¸°
                continue

        # âœ… ë‚¨ì€ ë°ì´í„° ë§ˆì§€ë§‰ ë°°ì¹˜ ì—…ë°ì´íŠ¸
        if batch_cells:
            print(f"\nğŸ“¤ ìµœì¢… ë°°ì¹˜ ì—…ë°ì´íŠ¸: {batch_rows_count}í–‰, {len(batch_cells)}ê°œ ì…€")
            worksheet.update_cells(batch_cells)
            print(f"âœ… ìµœì¢… ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

        elapsed_time = time.time() - start_time
        print("\n" + "=" * 60)
        print("ğŸ“Š ìµœì¢… ê²°ê³¼")
        print("=" * 60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time / 60:.1f}ë¶„")
        if (success_count + fail_count) > 0:
            print(f"âš¡ í‰ê·  ì†ë„: {elapsed_time / (success_count + fail_count):.1f}ì´ˆ/ì±„ë„")
        print("=" * 60)

        api_manager.sync_to_sheet()
        api_manager.print_status()

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

# ========================================
# 13. ì‹¤í–‰
# ========================================
if __name__ == '__main__':
    main()
